from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import logging
import traceback
import uuid
import json
import socket
from contextlib import asynccontextmanager, closing
from typing import Dict, Optional, List, Union
from maindouble import LearningAssistantSystem
import uvicorn
import asyncio
from concurrent.futures import ProcessPoolExecutor
import os
# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# å…¨å±€è¿›ç¨‹æ± 
process_pool = ProcessPoolExecutor()

# åº”ç”¨ç¨‹åºç”Ÿå‘½å‘¨æœŸç®¡ç†
@asynccontextmanager
async def lifespan(app: FastAPI):
    """ç®¡ç†åº”ç”¨ç”Ÿå‘½å‘¨æœŸ"""
    logger.info("ğŸš€ å­¦ä¹ åŠ©æ‰‹APIæœåŠ¡å¯åŠ¨ä¸­...")
    try:
        # åˆå§‹åŒ–ç³»ç»Ÿ
        app.state.system = LearningAssistantSystem()
        logger.info("âœ… å­¦ä¹ åŠ©æ‰‹ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        yield
    except Exception as e:
        logger.error(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")
        raise
    finally:
        logger.info("ğŸ›‘ å­¦ä¹ åŠ©æ‰‹APIæœåŠ¡å…³é—­")
        process_pool.shutdown(wait=True)

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="æ™ºèƒ½å­¦ä¹ åŠ©æ‰‹API",
    description="æä¾›å®Œæ•´çš„é”™é¢˜åˆ†æå’Œå­¦ä¹ å»ºè®®ç”ŸæˆæœåŠ¡",
    version="2.0.0",
    lifespan=lifespan,
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORSè®¾ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ•°æ®æ¨¡å‹
class AnalysisRequest(BaseModel):
    error_description: str
    user_id: Optional[str] = None
    request_id: Optional[str] = None

class AnalysisResponse(BaseModel):
    """åˆ†æç»“æœå“åº”æ¨¡å‹"""
    content: str
    request_id: str
    user_id: str
    status: str = "completed"
    processing_time_ms: Optional[int] = None

# ç”¨æˆ·ä¼šè¯å­˜å‚¨
user_sessions: Dict[str, dict] = {}

# å·¥å…·å‡½æ•°
def generate_id(prefix: str = "") -> str:
    """ç”Ÿæˆå¸¦å‰ç¼€çš„å”¯ä¸€ID"""
    return f"{prefix}{uuid.uuid4().hex}"

def check_port(port: int, host: str = "0.0.0.0") -> bool:
    """æ£€æŸ¥ç«¯å£æ˜¯å¦å¯ç”¨"""
    with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as sock:
        return sock.connect_ex((host, port)) != 0

def find_available_port(base_port: int = 8000, max_tries: int = 10) -> int:
    """è‡ªåŠ¨å¯»æ‰¾å¯ç”¨ç«¯å£"""
    for port in range(base_port, base_port + max_tries):
        if check_port(port):
            return port
    raise OSError(f"æ²¡æœ‰å¯ç”¨çš„ç«¯å£ (å°è¯•èŒƒå›´: {base_port}-{base_port + max_tries - 1})")

def run_analysis_pipeline(system: LearningAssistantSystem, error_description: str):
    """åŒ…è£…åŒæ­¥çš„pipelineå‡½æ•°ï¼Œç”¨äºè¿›ç¨‹æ± æ‰§è¡Œ"""
    return list(system.full_analysis_pipeline(error_description))

# æ ¸å¿ƒAPI
@app.post("/v1/analyze", response_class=StreamingResponse)
async def full_analysis_stream(request: AnalysisRequest):
    """
    å®Œæ•´åˆ†ææµç¨‹æ¥å£ (æµå¼+å®Œæ•´è¿”å›)
    ä½¿ç”¨è¿›ç¨‹æ± å¹¶è¡Œå¤„ç†CPUå¯†é›†å‹ä»»åŠ¡
    """
    # è¯·æ±‚æ ‡è¯†å¤„ç†
    request_id = request.request_id or generate_id("req_")
    user_id = request.user_id or generate_id("user_")
    
    # éªŒè¯è¾“å…¥
    if not request.error_description.strip():
        raise HTTPException(status_code=400, detail="é”™é¢˜æè¿°ä¸èƒ½ä¸ºç©º")
    
    # åˆå§‹åŒ–ç”¨æˆ·ä¼šè¯
    if user_id not in user_sessions:
        user_sessions[user_id] = {
            "current_analysis": request.error_description[:100] + "...",
            "request_count": 0
        }
    user_sessions[user_id]["request_count"] += 1
    
    logger.info(f"ğŸ“© æ”¶åˆ°åˆ†æè¯·æ±‚ [user={user_id}, req={request_id}]")

    async def analysis_generator():
        """åˆ†æç»“æœç”Ÿæˆå™¨"""
        full_response = ""
        try:
            # åˆå§‹å…ƒæ•°æ®
            yield json.dumps({
                "meta": {
                    "request_id": request_id,
                    "user_id": user_id,
                    "status": "started",
                    "phase": "initializing"
                }
            }) + "\n"
            
            # å°†CPUå¯†é›†å‹ä»»åŠ¡æ”¾å…¥è¿›ç¨‹æ± æ‰§è¡Œ
            loop = asyncio.get_event_loop()
            chunks = await loop.run_in_executor(
                process_pool,
                run_analysis_pipeline,
                app.state.system,
                request.error_description
            )
            
            # æµå¼è¿”å›ç»“æœ
            for chunk in chunks:
                full_response += chunk
                yield json.dumps({
                    "data": chunk,
                    "meta": {
                        "status": "streaming",
                        "bytes_received": len(full_response)
                    }
                }) + "\n"
            
            # æœ€ç»ˆå®Œæ•´ç»“æœ
            yield json.dumps({
                "data": full_response,
                "meta": {
                    "status": "completed",
                    "bytes_total": len(full_response),
                    "analysis_complete": True
                }
            }) + "\n"
            
            logger.info(f"âœ… åˆ†æå®Œæˆ [user={user_id}, req={request_id}, bytes={len(full_response)}]")
            
        except Exception as e:
            logger.error(f"âŒ åˆ†æå¤±è´¥ [user={user_id}, req={request_id}]: {str(e)}")
            logger.error(traceback.format_exc())
            yield json.dumps({
                "error": {
                    "code": 500,
                    "message": "åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯",
                    "details": str(e)
                },
                "meta": {
                    "request_id": request_id,
                    "status": "error"
                }
            }) + "\n"
        finally:
            # æ›´æ–°ç”¨æˆ·ä¼šè¯çŠ¶æ€
            user_sessions[user_id]["current_analysis"] = None

    return StreamingResponse(
        analysis_generator(),
        media_type="application/x-ndjson",
        headers={
            "X-Request-ID": request_id,
            "X-User-ID": user_id,
            "Cache-Control": "no-cache"
        }
    )

@app.post("/full-analysis/", response_model=AnalysisResponse) 
async def full_analysis_sync(request: AnalysisRequest):
    """
    å®Œæ•´åˆ†ææµç¨‹æ¥å£ (ä»…è¿”å›æœ€ç»ˆç»“æœ)
    ä½¿ç”¨è¿›ç¨‹æ± å¹¶è¡Œå¤„ç†CPUå¯†é›†å‹ä»»åŠ¡
    """
    # è¯·æ±‚æ ‡è¯†å¤„ç†
    request_id = request.request_id or generate_id("req_")
    user_id = request.user_id or generate_id("user_")
    
    # éªŒè¯è¾“å…¥
    if not request.error_description.strip():
        raise HTTPException(status_code=400, detail="é”™é¢˜æè¿°ä¸èƒ½ä¸ºç©º")
    
    # åˆå§‹åŒ–ç”¨æˆ·ä¼šè¯
    if user_id not in user_sessions:
        user_sessions[user_id] = {
            "current_analysis": request.error_description[:100] + "...",
            "request_count": 0
        }
    user_sessions[user_id]["request_count"] += 1
    
    logger.info(f"ğŸ“© æ”¶åˆ°åŒæ­¥åˆ†æè¯·æ±‚ [user={user_id}, req={request_id}]")

    try:
        # æ‰§è¡Œåˆ†ææµç¨‹å¹¶æ”¶é›†å®Œæ•´ç»“æœ
        import time
        start_time = time.time()
        
        loop = asyncio.get_event_loop()
        chunks = await loop.run_in_executor(
            process_pool,
            run_analysis_pipeline,
            app.state.system,
            request.error_description
        )
        
        full_response = "".join(chunks)
        processing_time = int((time.time() - start_time) * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
        
        logger.info(f"âœ… åŒæ­¥åˆ†æå®Œæˆ [user={user_id}, req={request_id}, bytes={len(full_response)}, time={processing_time}ms]")
        
        return AnalysisResponse(
            content=full_response,
            request_id=request_id,
            user_id=user_id,
            status="completed",
            processing_time_ms=processing_time
        )
            
    except Exception as e:
        logger.error(f"âŒ åŒæ­¥åˆ†æå¤±è´¥ [user={user_id}, req={request_id}]: {str(e)}")
        logger.error(traceback.format_exc())
        raise HTTPException(
            status_code=500,
            detail={
                "message": "åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯",
                "details": str(e),
                "request_id": request_id
            }
        )
    finally:
        # æ›´æ–°ç”¨æˆ·ä¼šè¯çŠ¶æ€
        user_sessions[user_id]["current_analysis"] = None

# è¾…åŠ©API
@app.get("/health")
async def health_check():
    """æœåŠ¡å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "version": app.version,
        "system": "available" if hasattr(app.state, "system") else "unavailable",
        "process_pool": "running" if not process_pool._shutdown else "shutdown"
    }

@app.get("/users/{user_id}/status")
async def get_user_status(user_id: str):
    """è·å–ç”¨æˆ·çŠ¶æ€"""
    if user_id in user_sessions:
        return {
            "user_id": user_id,
            "status": "active" if user_sessions[user_id]["current_analysis"] else "idle",
            "request_count": user_sessions[user_id]["request_count"],
            "current_analysis": user_sessions[user_id]["current_analysis"]
        }
    raise HTTPException(status_code=404, detail="ç”¨æˆ·æœªæ‰¾åˆ°")

if __name__ == "__main__":
    
    try:
        port = find_available_port(8000)
        logger.info(f"ğŸŒ å¯åŠ¨æœåŠ¡å™¨ 0.0.0.0:{port}")
        
        # ä½¿ç”¨æ¨¡å—å¯¼å…¥æ–¹å¼å¯åŠ¨
        uvicorn.run(
            "teachersever:app",  # æ¨¡å—å:åº”ç”¨å˜é‡å
            host="0.0.0.0", 
            port=port,
            workers=4,
            reload=False,  # ç”Ÿäº§ç¯å¢ƒè®¾ä¸ºFalse
            loop="asyncio",
            timeout_keep_alive=60
        )
    except Exception as e:
        logger.critical(f"ğŸ’¥ æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {str(e)}")
        raise