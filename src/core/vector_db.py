
#vector_db.py - æœ¬åœ°æ–‡æœ¬å‘é‡åŒ–åŠç´¢å¼•ç®¡ç†æ¨¡å—
import os
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'  # ä¼˜å…ˆä½¿ç”¨é•œåƒ

from pathlib import Path
import logging
from typing import List
import numpy as np

# ç¬¬ä¸‰æ–¹åº“å¯¼å…¥
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

class VectorDB:
    """å‘é‡æ•°æ®åº“ç®¡ç†ç±»"""
    
    def __init__(
        self,
        model_path: str = "./model/embeddingmodel",
        device: str = "cpu",
        db_path: str = "./vector_db",
        chunk_size: int = 32
    ):
        """
        åˆå§‹åŒ–å‘é‡æ•°æ®åº“
        :param model_path: æœ¬åœ°æ¨¡å‹è·¯å¾„
        :param device: è®¡ç®—è®¾å¤‡ (cpu/cuda)
        :param db_path: å‘é‡æ•°æ®åº“å­˜å‚¨è·¯å¾„
        :param chunk_size: æ‰¹å¤„ç†å¤§å°
        """
        self._setup_logging()
        self.model_path = Path(model_path)
        self.db_path = Path(db_path)
        self.chunk_size = chunk_size
        
        try:
            self.embeddings = HuggingFaceEmbeddings(
                model_name=str(self.model_path.absolute()),
                model_kwargs={'device': device},
                encode_kwargs={
                    'batch_size': chunk_size,
                    'normalize_embeddings': False
                }
            )
            self.vector_db = None
            logging.info("âœ… åµŒå…¥æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logging.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            raise

    def _setup_logging(self):
        """é…ç½®æ—¥å¿—æ ¼å¼"""
        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s - %(levelname)s - %(module)s - %(message)s"
        )

    def process_chunks(self, chunks: List[str]) -> bool:
        """
        å¤„ç†æ–‡æœ¬å—ç”Ÿæˆå‘é‡ç´¢å¼•
        :param chunks: æ–‡æœ¬å—åˆ—è¡¨
        :return: å¤„ç†ç»“æœ
        """
        try:
            if not chunks:
                logging.warning("âš ï¸ æ¥æ”¶åˆ°ç©ºæ–‡æœ¬åˆ—è¡¨")
                return False

            # åˆ›å»ºæˆ–æ›´æ–°å‘é‡æ•°æ®åº“
            self.vector_db = FAISS.from_texts(
                texts=chunks,
                embedding=self.embeddings
            )
            logging.info(f"ğŸ¯ æˆåŠŸç”Ÿæˆ {len(chunks)} ä¸ªå‘é‡")
            return True
            
        except Exception as e:
            logging.error(f"âŒ å‘é‡ç”Ÿæˆå¤±è´¥: {str(e)}")
            return False

    def save_index(self) -> bool:
        """ä¿å­˜å‘é‡ç´¢å¼•åˆ°æœ¬åœ°"""
        if not self.vector_db:
            logging.error("âŒ è¯·å…ˆæ‰§è¡Œ process_chunks ç”Ÿæˆç´¢å¼•")
            return False
            
        try:
            self.db_path.mkdir(parents=True, exist_ok=True)
            self.vector_db.save_local(self.db_path)
            logging.info(f"ğŸ’¾ ç´¢å¼•å·²ä¿å­˜è‡³ {self.db_path}")
            return True
        except Exception as e:
            logging.error(f"âŒ ä¿å­˜å¤±è´¥: {str(e)}")
            return False

    def load_existing_index(self) -> bool:
        """åŠ è½½å·²æœ‰å‘é‡ç´¢å¼•"""
        try:
            if not (self.db_path / "index.faiss").exists():
                logging.warning("âš ï¸ æœªæ‰¾åˆ°å·²æœ‰ç´¢å¼•")
                return False
                
            self.vector_db = FAISS.load_local(
                folder_path=self.db_path,
                embeddings=self.embeddings,
                allow_dangerous_deserialization=True  # å…è®¸åŠ è½½æœªç»éªŒè¯çš„æ–‡ä»¶
            )
            logging.info("ğŸ” æˆåŠŸåŠ è½½å·²æœ‰ç´¢å¼•")
            return True
        except Exception as e:
            logging.error(f"âŒ ç´¢å¼•åŠ è½½å¤±è´¥: {str(e)}")
            return False

# ---------------------------- æµ‹è¯•ä»£ç  ----------------------------
if __name__ == "__main__":
    # æµ‹è¯•é…ç½®
    test_chunks = [
        "é‡å­è®¡ç®—åˆ©ç”¨é‡å­æ¯”ç‰¹å®ç°å¹¶è¡Œè®¡ç®—",
        "Transformeræ¨¡å‹åœ¨NLPé¢†åŸŸå¹¿æ³›åº”ç”¨",
        "è”é‚¦å­¦ä¹ ä¿æŠ¤ç”¨æˆ·æ•°æ®éšç§",
        "LangChainç®€åŒ–äº†AIåº”ç”¨å¼€å‘æµç¨‹"
    ]

    # åˆå§‹åŒ–æ•°æ®åº“
    try:
        vdb = VectorDB(
            model_path="./model/embeddingmodel",
            device="cpu",
            db_path="./test_vector_db"
        )
        
        # å¤„ç†æ–‡æœ¬ç”Ÿæˆå‘é‡
        if vdb.process_chunks(test_chunks):
            # ä¿å­˜ç´¢å¼•
            if vdb.save_index():
                # éªŒè¯å‘é‡ç»´åº¦
                sample_vector = vdb.embeddings.embed_query(test_chunks[0])
                print("\n=== æµ‹è¯•ç»“æœ ===")
                print(f"å‘é‡ç»´åº¦: {len(sample_vector)}")
                print(f"é¦–å‘é‡å‰5ç»´: {np.round(sample_vector[:5], 4)}")
                
                # éªŒè¯ç´¢å¼•åŠ è½½
                if vdb.load_existing_index():
                    print(f"ç´¢å¼•æ–‡æ¡£æ•°: {vdb.vector_db.index.ntotal}")
                
    except Exception as e:
        print(f"â— æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {str(e)}")
        print("æ•…éšœæ’æŸ¥å»ºè®®ï¼šæ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´ï¼Œç¡®ä¿å®‰è£…æ‰€æœ‰ä¾èµ–åº“")