from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import logging
import traceback
import uuid
import json
import socket
from contextlib import asynccontextmanager, closing
from typing import Dict, Optional, List, Union, Any
from maindouble import LearningAssistantSystem
import uvicorn
import asyncio
from collections import defaultdict

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# å¹¶å‘æ§åˆ¶è®¾ç½®
MAX_CONCURRENT_REQUESTS = 100  # æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
REQUEST_TIMEOUT = 300  # è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)

# åº”ç”¨ç¨‹åºç”Ÿå‘½å‘¨æœŸç®¡ç†
@asynccontextmanager
async def lifespan(app: FastAPI):
    """ç®¡ç†åº”ç”¨ç”Ÿå‘½å‘¨æœŸ"""
    logger.info("ğŸš€ å­¦ä¹ åŠ©æ‰‹APIæœåŠ¡å¯åŠ¨ä¸­...")
    try:
        # åˆå§‹åŒ–ç³»ç»Ÿ
        app.state.system = LearningAssistantSystem()
        # åˆå§‹åŒ–å¹¶å‘æ§åˆ¶
        app.state.semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)
        # åˆå§‹åŒ–è¯·æ±‚é”
        app.state.request_locks = defaultdict(asyncio.Lock)
        logger.info("âœ… å­¦ä¹ åŠ©æ‰‹ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        yield
    except Exception as e:
        logger.error(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")
        raise
    finally:
        logger.info("ğŸ›‘ å­¦ä¹ åŠ©æ‰‹APIæœåŠ¡å…³é—­")

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="æ™ºèƒ½å­¦ä¹ åŠ©æ‰‹API",
    description="æä¾›å®Œæ•´çš„é”™é¢˜åˆ†æå’Œå­¦ä¹ å»ºè®®ç”ŸæˆæœåŠ¡",
    version="2.0.0",
    lifespan=lifespan,
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORSè®¾ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ•°æ®æ¨¡å‹
class AnalysisRequest(BaseModel):
    error_description: str
    user_id: Optional[str] = None
    request_id: Optional[str] = None

class AnalysisResponse(BaseModel):
    """åˆ†æç»“æœå“åº”æ¨¡å‹"""
    content: str
    request_id: str
    user_id: str
    status: str = "completed"
    processing_time_ms: Optional[int] = None

# ç”¨æˆ·ä¼šè¯å­˜å‚¨ - ä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„æ•°æ®ç»“æ„
user_sessions: Dict[str, Dict[str, Any]] = defaultdict(lambda: {
    "current_analysis": None,
    "request_count": 0,
    "lock": asyncio.Lock()
})

# å·¥å…·å‡½æ•°
def generate_id(prefix: str = "") -> str:
    """ç”Ÿæˆå¸¦å‰ç¼€çš„å”¯ä¸€ID"""
    return f"{prefix}{uuid.uuid4().hex}"

def check_port(port: int, host: str = "0.0.0.0") -> bool:
    """æ£€æŸ¥ç«¯å£æ˜¯å¦å¯ç”¨"""
    with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as sock:
        sock.settimeout(1)
        try:
            result = sock.connect_ex((host, port))
            return result != 0  # è¿”å›Trueè¡¨ç¤ºç«¯å£å¯ç”¨ï¼ŒFalseè¡¨ç¤ºç«¯å£è¢«å ç”¨
        except socket.error as e:
            logger.error(f"æ£€æŸ¥ç«¯å£æ—¶å‡ºé”™: {e}")
            return False

def find_available_port(base_port: int = 8000, max_tries: int = 10) -> int:
    """è‡ªåŠ¨å¯»æ‰¾å¯ç”¨ç«¯å£"""
    logger.info(f"æ­£åœ¨æŸ¥æ‰¾å¯ç”¨ç«¯å£ï¼Œä» {base_port} å¼€å§‹ï¼Œå°è¯• {max_tries} æ¬¡")
    for attempt in range(max_tries):
        port = base_port + attempt
        if check_port(port):
            logger.info(f"æ‰¾åˆ°å¯ç”¨ç«¯å£: {port}")
            return port
        else:
            logger.warning(f"ç«¯å£ {port} å·²è¢«å ç”¨ï¼Œå°è¯•ä¸‹ä¸€ä¸ª")
    
    logger.error(f"æ²¡æœ‰æ‰¾åˆ°å¯ç”¨ç«¯å£ (å°è¯•èŒƒå›´: {base_port}-{base_port + max_tries - 1})")
    raise OSError(f"æ²¡æœ‰å¯ç”¨çš„ç«¯å£ (å°è¯•èŒƒå›´: {base_port}-{base_port + max_tries - 1})")

# æ ¸å¿ƒAPI
@app.post("/v1/analyze", response_class=StreamingResponse)
async def full_analysis_stream(request: AnalysisRequest):
    """
    å®Œæ•´åˆ†ææµç¨‹æ¥å£ (æµå¼+å®Œæ•´è¿”å›)
    """
    logger.info(f"æ”¶åˆ°æµå¼åˆ†æè¯·æ±‚: {request.dict()}")
    # è¯·æ±‚æ ‡è¯†å¤„ç†
    request_id = request.request_id or generate_id("req_")
    user_id = request.user_id or generate_id("user_")
    
    # éªŒè¯è¾“å…¥
    if not request.error_description.strip():
        raise HTTPException(status_code=400, detail="é”™é¢˜æè¿°ä¸èƒ½ä¸ºç©º")
    
    # è·å–ç”¨æˆ·ä¼šè¯é”
    user_lock = user_sessions[user_id]["lock"]
    
    async with app.state.semaphore, user_lock:
        try:
            # æ›´æ–°ç”¨æˆ·ä¼šè¯çŠ¶æ€
            async with user_lock:
                user_sessions[user_id]["current_analysis"] = request.error_description[:100] + "..."
                user_sessions[user_id]["request_count"] += 1
            
            logger.info(f"ğŸ“© æ”¶åˆ°åˆ†æè¯·æ±‚ [user={user_id}, req={request_id}]")

            async def analysis_generator():
                """åˆ†æç»“æœç”Ÿæˆå™¨"""
                full_response = ""
                try:
                    # åˆå§‹å…ƒæ•°æ®
                    yield json.dumps({
                        "meta": {
                            "request_id": request_id,
                            "user_id": user_id,
                            "status": "started",
                            "phase": "initializing"
                        }
                    }) + "\n"
                    
                    # æ‰§è¡Œåˆ†ææµç¨‹
                    for chunk in app.state.system.full_analysis_pipeline(request.error_description):
                        full_response += chunk
                        yield json.dumps({
                            "data": chunk,
                            "meta": {
                                "status": "streaming",
                                "bytes_received": len(full_response)
                            }
                        }) + "\n"
                    
                    # æœ€ç»ˆå®Œæ•´ç»“æœ
                    yield json.dumps({
                        "data": full_response,
                        "meta": {
                            "status": "completed",
                            "bytes_total": len(full_response),
                            "analysis_complete": True
                        }
                    }) + "\n"
                    
                    logger.info(f"âœ… åˆ†æå®Œæˆ [user={user_id}, req={request_id}, bytes={len(full_response)}]")
                    
                except Exception as e:
                    logger.error(f"âŒ åˆ†æå¤±è´¥ [user={user_id}, req={request_id}]: {str(e)}")
                    logger.error(traceback.format_exc())
                    yield json.dumps({
                        "error": {
                            "code": 500,
                            "message": "åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯",
                            "details": str(e)
                        },
                        "meta": {
                            "request_id": request_id,
                            "status": "error"
                        }
                    }) + "\n"
                finally:
                    # æ›´æ–°ç”¨æˆ·ä¼šè¯çŠ¶æ€
                    async with user_lock:
                        user_sessions[user_id]["current_analysis"] = None

            return StreamingResponse(
                analysis_generator(),
                media_type="application/x-ndjson",
                headers={
                    "X-Request-ID": request_id,
                    "X-User-ID": user_id,
                    "Cache-Control": "no-cache"
                }
            )
            
        except asyncio.TimeoutError:
            logger.error(f"â±ï¸ è¯·æ±‚è¶…æ—¶ [user={user_id}, req={request_id}]")
            raise HTTPException(status_code=504, detail="è¯·æ±‚å¤„ç†è¶…æ—¶")
        except Exception as e:
            logger.error(f"âŒ è¯·æ±‚å¤„ç†é”™è¯¯ [user={user_id}, req={request_id}]: {str(e)}")
            raise HTTPException(status_code=500, detail=str(e))

@app.post("/full-analysis/", response_model=AnalysisResponse) 
async def full_analysis_sync(request: AnalysisRequest):
    """
    å®Œæ•´åˆ†ææµç¨‹æ¥å£ (ä»…è¿”å›æœ€ç»ˆç»“æœ)
    """
    logger.info(f"æ”¶åˆ°åŒæ­¥åˆ†æè¯·æ±‚: {request.dict()}")
    # è¯·æ±‚æ ‡è¯†å¤„ç†
    request_id = request.request_id or generate_id("req_")
    user_id = request.user_id or generate_id("user_")
    
    # éªŒè¯è¾“å…¥
    if not request.error_description.strip():
        raise HTTPException(status_code=400, detail="é”™é¢˜æè¿°ä¸èƒ½ä¸ºç©º")
    
    # è·å–ç”¨æˆ·ä¼šè¯é”
    user_lock = user_sessions[user_id]["lock"]
    
    async with app.state.semaphore, user_lock:
        try:
            # æ›´æ–°ç”¨æˆ·ä¼šè¯çŠ¶æ€
            async with user_lock:
                user_sessions[user_id]["current_analysis"] = request.error_description[:100] + "..."
                user_sessions[user_id]["request_count"] += 1
            
            logger.info(f"ğŸ“© æ”¶åˆ°åŒæ­¥åˆ†æè¯·æ±‚ [user={user_id}, req={request_id}]")

            # æ‰§è¡Œåˆ†ææµç¨‹å¹¶æ”¶é›†å®Œæ•´ç»“æœ
            import time
            start_time = time.time()
            
            full_response = ""
            for chunk in app.state.system.full_analysis_pipeline(request.error_description):
                full_response += chunk
                
            processing_time = int((time.time() - start_time) * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
            
            logger.info(f"âœ… åŒæ­¥åˆ†æå®Œæˆ [user={user_id}, req={request_id}, bytes={len(full_response)}, time={processing_time}ms]")
            
            return AnalysisResponse(
                content=full_response,
                request_id=request_id,
                user_id=user_id,
                status="completed",
                processing_time_ms=processing_time
            )
                
        except asyncio.TimeoutError:
            logger.error(f"â±ï¸ åŒæ­¥è¯·æ±‚è¶…æ—¶ [user={user_id}, req={request_id}]")
            raise HTTPException(status_code=504, detail="è¯·æ±‚å¤„ç†è¶…æ—¶")
        except Exception as e:
            logger.error(f"âŒ åŒæ­¥åˆ†æå¤±è´¥ [user={user_id}, req={request_id}]: {str(e)}")
            logger.error(traceback.format_exc())
            raise HTTPException(
                status_code=500,
                detail={
                    "message": "åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯",
                    "details": str(e),
                    "request_id": request_id
                }
            )
        finally:
            # æ›´æ–°ç”¨æˆ·ä¼šè¯çŠ¶æ€
            async with user_lock:
                user_sessions[user_id]["current_analysis"] = None

# è¾…åŠ©API
@app.get("/health")
async def health_check():
    """æœåŠ¡å¥åº·æ£€æŸ¥"""
    logger.info("æ”¶åˆ°å¥åº·æ£€æŸ¥è¯·æ±‚")
    result = {
        "status": "healthy",
        "version": app.version,
        "system": "available" if hasattr(app.state, "system") else "unavailable",
        "concurrent_requests": MAX_CONCURRENT_REQUESTS - app.state.semaphore._value if hasattr(app.state, "semaphore") else 0,
        "max_concurrent_requests": MAX_CONCURRENT_REQUESTS
    }
    logger.info(f"å¥åº·æ£€æŸ¥è¿”å›: {result}")
    return result

@app.get("/users/{user_id}/status")
async def get_user_status(user_id: str):
    """è·å–ç”¨æˆ·çŠ¶æ€"""
    if user_id in user_sessions:
        async with user_sessions[user_id]["lock"]:
            return {
                "user_id": user_id,
                "status": "active" if user_sessions[user_id]["current_analysis"] else "idle",
                "request_count": user_sessions[user_id]["request_count"],
                "current_analysis": user_sessions[user_id]["current_analysis"]
            }
    raise HTTPException(status_code=404, detail="ç”¨æˆ·æœªæ‰¾åˆ°")

if __name__ == "__main__":
    try:
        port = find_available_port(8000)
        logger.info(f"ğŸŒ æœåŠ¡å™¨å°†åœ¨ 0.0.0.0:{port} å¯åŠ¨")
        
        # ä½¿ç”¨æ¨¡å—å¯¼å…¥å­—ç¬¦ä¸²å½¢å¼
        uvicorn.run(
            "fastsever4:app",  # æ”¹ä¸ºæ¨¡å—å:åº”ç”¨å˜é‡å
            host="0.0.0.0", 
            port=port,
            workers=4,
            limit_concurrency=MAX_CONCURRENT_REQUESTS,
            timeout_keep_alive=REQUEST_TIMEOUT,
            log_level="info",  # ç¡®ä¿æ—¥å¿—çº§åˆ«è®¾ç½®ä¸ºinfo
            reload=True  # å¦‚æœéœ€è¦çƒ­é‡è½½å¯ä»¥æ·»åŠ è¿™ä¸ª
        )
    except Exception as e:
        logger.critical(f"ğŸ’¥ æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {str(e)}")
        raise